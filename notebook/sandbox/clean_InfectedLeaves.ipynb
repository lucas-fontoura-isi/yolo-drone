{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a4ead9c",
   "metadata": {},
   "source": [
    "# Scripts to clean the original dataset used at \"Bacterial-fungicidal vine disease detection with proximal aerial images\" also called \"InfectedLeaves\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be8e4f7",
   "metadata": {},
   "source": [
    "## COCO json cleaning\n",
    "\n",
    "- Deleting ids that are not present in the images folder\n",
    "- Deleting ids that have an area below 1\n",
    "- Rearange ids number\n",
    "- Scale bounding boxes to match images real size (3840x2160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce60462",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# -------- CONFIG ----------\n",
    "images_folder = \"../../data/datasets/VeryReduced_InfectedLeaves/images\"\n",
    "input_json = \"../../data/datasets/VeryReduced_InfectedLeaves/annotations/_annotations.coco.fixed.json\"\n",
    "output_json = \"../../data/datasets/VeryReduced_InfectedLeaves/annotations/_annotations.coco-cleaned.fixed.json\"\n",
    "\n",
    "# Scaling factors (from 640x360 → 3840x2160)\n",
    "scale_x = 3840 / 640\n",
    "scale_y = 2160 / 360\n",
    "\n",
    "reassign_image_ids = True\n",
    "reassign_annotation_ids = True\n",
    "keep_original_ids = False\n",
    "keep_original_fname = False\n",
    "# ---------------------------\n",
    "\n",
    "\n",
    "def clean_filename(fname: str) -> str:\n",
    "    return re.sub(r\"_jpg\\.rf\\.[0-9a-f]+\\.(jpg|jpeg|png)$\", r\".\\1\", fname, flags=re.IGNORECASE)\n",
    "\n",
    "# Load COCO JSON\n",
    "with open(input_json, \"r\", encoding=\"utf-8\") as f:\n",
    "    coco = json.load(f)\n",
    "\n",
    "# List existing files (cleaned + lowercased)\n",
    "p = Path(images_folder)\n",
    "existing_files = {clean_filename(p_.name).lower().strip() for p_ in p.iterdir() if p_.is_file()}\n",
    "\n",
    "# Filter images and create mapping old_id -> new_id\n",
    "oldid_to_newid = {}\n",
    "kept_images = []\n",
    "dropped_images = []\n",
    "\n",
    "next_img_id = 1\n",
    "for img in coco.get(\"images\", []):\n",
    "    original_fname = os.path.basename(img.get(\"file_name\", \"\")).strip()\n",
    "    clean_fname = clean_filename(original_fname)\n",
    "\n",
    "    if clean_fname.lower() in existing_files:\n",
    "        img_copy = img.copy()\n",
    "        if keep_original_fname:\n",
    "            img_copy[\"original_file_name\"] = img_copy[\"file_name\"]\n",
    "        img_copy[\"file_name\"] = clean_fname\n",
    "\n",
    "        old_id = img[\"id\"]\n",
    "        if reassign_image_ids:\n",
    "            if keep_original_ids:\n",
    "                img_copy[\"original_id\"] = old_id\n",
    "            img_copy[\"id\"] = next_img_id\n",
    "            oldid_to_newid[old_id] = next_img_id\n",
    "            next_img_id += 1\n",
    "        else:\n",
    "            oldid_to_newid[old_id] = old_id\n",
    "\n",
    "        kept_images.append(img_copy)\n",
    "    else:\n",
    "        dropped_images.append(original_fname)\n",
    "\n",
    "# Filter & remap annotations\n",
    "kept_annotations = []\n",
    "dropped_annotations = []\n",
    "dropped_small_annotations = []\n",
    "next_ann_id = 1\n",
    "for ann in coco.get(\"annotations\", []):\n",
    "    old_img_id = ann[\"image_id\"]\n",
    "    if old_img_id in oldid_to_newid:\n",
    "        if ann.get(\"area\", 0) < 1:\n",
    "            dropped_small_annotations.append(ann.get(\"id\"))\n",
    "            continue\n",
    "\n",
    "        ann_copy = ann.copy()\n",
    "        ann_copy[\"image_id\"] = oldid_to_newid[old_img_id]\n",
    "\n",
    "        # Rescale bbox\n",
    "        if \"bbox\" in ann_copy:\n",
    "            x, y, w, h = ann_copy[\"bbox\"]\n",
    "            x *= scale_x\n",
    "            y *= scale_y\n",
    "            w *= scale_x\n",
    "            h *= scale_y\n",
    "            ann_copy[\"bbox\"] = [x, y, w, h]\n",
    "\n",
    "            # Update area as well\n",
    "            ann_copy[\"area\"] = w * h\n",
    "\n",
    "        # optionally reassign annotation id\n",
    "        if reassign_annotation_ids:\n",
    "            if keep_original_ids:\n",
    "                ann_copy[\"original_id\"] = ann[\"id\"]\n",
    "            ann_copy[\"id\"] = next_ann_id\n",
    "            next_ann_id += 1\n",
    "\n",
    "        kept_annotations.append(ann_copy)\n",
    "    else:\n",
    "        dropped_annotations.append(ann.get(\"id\"))\n",
    "\n",
    "# Build final COCO dict\n",
    "filtered_coco = {\n",
    "    \"info\": coco.get(\"info\", {}),\n",
    "    \"licenses\": coco.get(\"licenses\", []),\n",
    "    \"categories\": coco.get(\"categories\", []),\n",
    "    \"images\": kept_images,\n",
    "    \"annotations\": kept_annotations,\n",
    "}\n",
    "\n",
    "# Save\n",
    "with open(output_json, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(filtered_coco, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "# Summary\n",
    "print(f\"Images kept: {len(kept_images)}\")\n",
    "print(f\"Images dropped (not found): {len(dropped_images)}\")\n",
    "if dropped_images:\n",
    "    print(\"Dropped image files (examples):\", dropped_images[:10])\n",
    "print(f\"Annotations kept: {len(kept_annotations)}\")\n",
    "print(f\"Annotations dropped (missing images): {len(dropped_annotations)}\")\n",
    "if dropped_annotations:\n",
    "    print(\"Dropped annotation ids (examples):\", dropped_annotations[:10])\n",
    "print(f\"Annotations dropped (area < 1 px): {len(dropped_small_annotations)}\")\n",
    "if dropped_small_annotations:\n",
    "    print(\"Dropped small annotation ids (examples):\", dropped_small_annotations[:10])\n",
    "print(f\"✅ Rescaled bboxes saved to {output_json}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3febe7",
   "metadata": {},
   "source": [
    "## Slice windows with Sahi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8c4224",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sahi.slicing import slice_coco\n",
    "\n",
    "coco_dict, coco_path = slice_coco(\n",
    "    coco_annotation_file_path=\"../../data/datasets/VeryReduced_InfectedLeaves/annotations/_annotations.coco-cleaned.fixed.json\",\n",
    "    image_dir=\"../../data/datasets/VeryReduced_InfectedLeaves/images/\",\n",
    "    slice_height=640,\n",
    "    slice_width=640,\n",
    "    overlap_height_ratio=0.2,\n",
    "    overlap_width_ratio=0.2,\n",
    "    ignore_negative_samples=True,\n",
    "    output_coco_annotation_file_name=\"slice_coco_annotations.json\",\n",
    "    output_dir=\"sliced\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3911818",
   "metadata": {},
   "source": [
    "## Convert the original coco-style dataset to the expected by YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85064fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "# Config\n",
    "coco_json = Path(\"sliced/annotations/sliced.json\")\n",
    "images_dir = Path(\"sliced/images/\")\n",
    "output_dir = Path(\"veryreduced-yolodrone-sliced\")\n",
    "train_ratio = 0.8  # 80% train, 20% val\n",
    "\n",
    "# Make directories\n",
    "(output_dir / \"images/train\").mkdir(parents=True, exist_ok=True)\n",
    "(output_dir / \"images/val\").mkdir(parents=True, exist_ok=True)\n",
    "(output_dir / \"labels/train\").mkdir(parents=True, exist_ok=True)\n",
    "(output_dir / \"labels/val\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load COCO annotations\n",
    "with open(coco_json, \"r\") as f:\n",
    "    coco = json.load(f)\n",
    "\n",
    "# Function to clean filenames\n",
    "def clean_filename(filename: str) -> str:\n",
    "    # Replace \"_jpg...\" until the end with \".jpg\"\n",
    "    return re.sub(r\"_jpg.*\", \".jpg\", filename)\n",
    "\n",
    "# Build lookup tables\n",
    "image_id_to_filename = {img[\"id\"]: clean_filename(img[\"file_name\"]) for img in coco[\"images\"]}\n",
    "image_id_to_size = {img[\"id\"]: (img[\"width\"], img[\"height\"]) for img in coco[\"images\"]}\n",
    "\n",
    "# Clean and deduplicate category names\n",
    "cleaned_names = []\n",
    "cat_id_to_newid = {}\n",
    "for cat in coco[\"categories\"]:\n",
    "    name = cat[\"name\"].strip()\n",
    "    if name not in cleaned_names:\n",
    "        cleaned_names.append(name)\n",
    "    cat_id_to_newid[cat[\"id\"]] = cleaned_names.index(name)\n",
    "\n",
    "categories = cat_id_to_newid\n",
    "class_names = cleaned_names\n",
    "\n",
    "# Collect annotations per image\n",
    "annotations_per_image = {img_id: [] for img_id in image_id_to_filename.keys()}\n",
    "\n",
    "for ann in coco[\"annotations\"]:\n",
    "    img_id = ann[\"image_id\"]\n",
    "    cat_id = ann[\"category_id\"]\n",
    "    bbox = ann[\"bbox\"]  # COCO: [x_min, y_min, width, height]\n",
    "\n",
    "    # Get image size\n",
    "    img_w, img_h = image_id_to_size[img_id]\n",
    "\n",
    "    # Convert to YOLO format\n",
    "    x_min, y_min, w, h = bbox\n",
    "    x_center = (x_min + w / 2) / img_w\n",
    "    y_center = (y_min + h / 2) / img_h\n",
    "    w /= img_w\n",
    "    h /= img_h\n",
    "\n",
    "    class_id = categories[cat_id]\n",
    "    annotations_per_image[img_id].append([class_id, x_center, y_center, w, h])\n",
    "\n",
    "# Shuffle and split dataset\n",
    "image_ids = list(image_id_to_filename.keys())\n",
    "random.shuffle(image_ids)\n",
    "split_idx = int(len(image_ids) * train_ratio)\n",
    "train_ids, val_ids = image_ids[:split_idx], image_ids[split_idx:]\n",
    "\n",
    "# Helper to copy and write annotations\n",
    "def process_split(ids, split):\n",
    "    for img_id in ids:\n",
    "        filename = image_id_to_filename[img_id]\n",
    "        src_img = images_dir / filename\n",
    "        dst_img = output_dir / f\"images/{split}/{filename}\"\n",
    "\n",
    "        if not src_img.exists():\n",
    "            print(f\"⚠️ Warning: Image not found {src_img}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Symlink image\n",
    "        os.symlink(src_img.absolute(), dst_img)\n",
    "\n",
    "        # Write label\n",
    "        label_file = output_dir / f\"labels/{split}/{Path(filename).stem}.txt\"\n",
    "        with open(label_file, \"w\") as f:\n",
    "            for ann in annotations_per_image[img_id]:\n",
    "                f.write(\" \".join([f\"{a:.6f}\" if isinstance(a, float) else str(a) for a in ann]) + \"\\n\")\n",
    "\n",
    "# Process train and val splits\n",
    "process_split(train_ids, \"train\")\n",
    "process_split(val_ids, \"val\")\n",
    "\n",
    "# Write data.yaml\n",
    "yaml_content = f\"\"\"train: images/train\n",
    "val: images/val\n",
    "\n",
    "nc: {len(class_names)}\n",
    "names: {class_names}\n",
    "\"\"\"\n",
    "\n",
    "with open(output_dir / \"data.yaml\", \"w\") as f:\n",
    "    f.write(yaml_content)\n",
    "\n",
    "print(f\"✅ Conversion complete! YOLO dataset ready at: {output_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
